{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83671eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from newsapi import NewsApiClient\n",
    "from datetime import datetime, timedelta\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from random import sample\n",
    "import spacy\n",
    "from gdeltdoc import GdeltDoc, Filters\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16426a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gasto\\AppData\\Local\\Temp\\ipykernel_25824\\2353703816.py:16: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  end = datetime.utcnow()\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price       Date          price    return       date\n",
      "0     2025-10-26  114472.445312       NaN 2025-10-26\n",
      "1     2025-10-27  114119.328125 -0.003085 2025-10-27\n",
      "2     2025-10-28  112956.164062 -0.010193 2025-10-28\n",
      "3     2025-10-29  110055.304688 -0.025681 2025-10-29\n",
      "4     2025-10-30  108305.546875 -0.015899 2025-10-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------- Settings --------\n",
    "ASSET = \"BTC-USD\"  # asset to analyze from Yahoo Finance\n",
    "QUERIES = {\n",
    "     \"bitcoin\",\"crypto\",\"cryptocurrency\",\"ethereum\",\"blockchain\",\n",
    "    \"binance\",\"coinbase\",\"solana\",\"xrp\",\"defi\",\"web3\",\"nft\",\n",
    "    \"mining\",\"hashrate\",\"regulation\",\"hack\",\"exchange\",\"stablecoin\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "  # keywords to search for in news sources\n",
    "N_DAYS = 30  # number of days to analyze\n",
    "NEWSAPI_KEY = \"5bcdfd2037114aa591e1cff0ccd93b81\" \n",
    "\n",
    "# -------- 1. Get Prices --------\n",
    "end = datetime.utcnow()\n",
    "start = end - timedelta(days=N_DAYS + 5)  # margin of 5 days to ensure enough data\n",
    "\n",
    "prices = yf.download(ASSET, start=start, end=end, interval=\"1d\", group_by=\"column\")\n",
    "\n",
    "if isinstance(prices.columns, pd.MultiIndex):\n",
    "    prices.columns = prices.columns.get_level_values(0)\n",
    "    \n",
    "    \n",
    "prices = prices[[\"Close\"]].rename(columns={\"Close\": \"price\"})\n",
    "prices[\"return\"] = prices[\"price\"].pct_change()\n",
    "\n",
    "prices = prices.reset_index()    \n",
    "prices[\"date\"] = prices[\"Date\"].dt.normalize()\n",
    "prices_daily = prices[[\"date\", \"price\", \"return\"]]\n",
    "\n",
    "print(prices.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bced8b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockchain: 250 articles\n",
      "Skip 'nft' → The query was not valid. The API error message was: The specified phrase is too short.\n",
      "regulation: 250 articles\n",
      "Skip 'web3' → The query was not valid. The API error message was: The specified phrase is too short.\n",
      "stablecoin: 250 articles\n",
      "binance: 250 articles\n",
      "mining: 250 articles\n",
      "Skip 'hack' → The query was not valid. The API error message was: The specified phrase is too short.\n",
      "bitcoin: 250 articles\n",
      "exchange: 250 articles\n",
      "Skip 'defi' → The query was not valid. The API error message was: The specified phrase is too short.\n",
      "crypto: 250 articles\n",
      "coinbase: 250 articles\n",
      "hashrate: 130 articles\n",
      "Skip 'xrp' → The query was not valid. The API error message was: The specified phrase is too short.\n",
      "solana: 250 articles\n",
      "cryptocurrency: 250 articles\n",
      "ethereum: 250 articles\n",
      "Unique URLs: 2842\n"
     ]
    }
   ],
   "source": [
    "#-------- 2. Get news from GDELT --------\n",
    "\n",
    "gd = GdeltDoc()\n",
    "\n",
    "start_date = (end - timedelta(days=N_DAYS)).strftime(\"%Y-%m-%d\")\n",
    "end_date   = end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "all_news = []\n",
    "\n",
    "for q in QUERIES:\n",
    "  \n",
    "\n",
    "    f = Filters(\n",
    "        keyword=q,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        num_records=250,\n",
    "        language=\"English\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        df_q = gd.article_search(f)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skip '{q}' → {e}\")\n",
    "        continue\n",
    "\n",
    "    if df_q is None or df_q.empty:\n",
    "        print(f\"{q}: 0 articles\")\n",
    "        continue\n",
    "\n",
    "    df_q[\"query\"] = q\n",
    "    print(f\"{q}: {len(df_q)} articles\")\n",
    "    all_news.append(df_q)\n",
    "\n",
    "news_raw = pd.concat(all_news, ignore_index=True)\n",
    "news_raw = news_raw.drop_duplicates(subset=\"url\")\n",
    "print(\"Unique URLs:\", len(news_raw))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d03af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gasto\\Documents\\MachineLearning_NLP\\projet_quant\\.venv\\Lib\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname PST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles scraped: 73\n",
      "0    COPENHAGEN, Denmark, Nov. 17, 2025 /PRNewswire...\n",
      "1    New Delhi [India], November 17: Digital South ...\n",
      "4    London, Nov. 06, 2025 (GLOBE NEWSWIRE) --\\n\\n\\...\n",
      "5    This content is provided by a sponsor\\n\\nAbu D...\n",
      "6    Binance Mumbai Blockchain Yatra 2025\\n\\nIndia’...\n",
      "Name: fulltext, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#-------- 3. Scrape full texts --------\n",
    "\n",
    "def fetch_article(url):\n",
    "    try:\n",
    "        article = Article(url, language=\"en\")\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        txt = article.text\n",
    "        return txt if len(txt) > 100 else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "urls_sample = news_raw[\"url\"].dropna().unique()[:100]  # first 100 URLs\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as ex:\n",
    "    fulltexts = list(ex.map(fetch_article, urls_sample))\n",
    "\n",
    "url_to_text = dict(zip(urls_sample, fulltexts))\n",
    "\n",
    "news_raw[\"fulltext\"] = news_raw[\"url\"].map(url_to_text)\n",
    "\n",
    "news_clean = news_raw.dropna(subset=[\"fulltext\"])\n",
    "print(\"Articles scraped:\", len(news_clean))\n",
    "print(news_clean[\"fulltext\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac15ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------- 5. Text cleaning with SpaCy --------\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\",\"parser\"])\n",
    "\n",
    "def clean_text_spacy(txt):\n",
    "    doc = nlp(txt.lower())\n",
    "    return \" \".join([\n",
    "        tok.lemma_\n",
    "        for tok in doc\n",
    "        if tok.is_alpha and not tok.is_stop and len(tok) > 2\n",
    "    ])\n",
    "\n",
    "news_clean[\"clean_text\"] = news_clean[\"fulltext\"].apply(clean_text_spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "428685ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 02:37:25,539 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 3/3 [00:02<00:00,  1.21it/s]\n",
      "2025-11-30 02:37:30,072 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-30 02:37:30,073 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-30 02:37:30,155 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-30 02:37:30,157 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-30 02:37:30,176 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-30 02:37:30,181 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-30 02:37:30,899 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haha topic\n",
      "-1    45\n",
      " 0    16\n",
      " 1    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "docs = news_clean[\"clean_text\"].tolist()\n",
    "\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "news_clean[\"topic\"] = topics\n",
    "news_clean[\"topic_probmax\"] = [\n",
    "    float(np.max(p)) if p is not None else np.nan for p in probs\n",
    "]\n",
    "\n",
    "print(\"haha\",news_clean[\"topic\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a6666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                  Name  \\\n",
      "0     -1     45   -1_blockchain_market_digital_global   \n",
      "1      0     16  0_payment_blockchain_stablecoin_user   \n",
      "2      1     12   1_blockchain_digital_asset_platform   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [blockchain, market, digital, global, technolo...   \n",
      "1  [payment, blockchain, stablecoin, user, bank, ...   \n",
      "2  [blockchain, digital, asset, platform, credit,...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [pnn dubai uae november mark new era vision me...  \n",
      "1  [alibaba partner jpmorgan launch tokenized pay...  \n",
      "2  [lcpc launch drive blockchain platform intelli...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:00, 89.30it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "news_df = news_clean.copy()\n",
    "\n",
    "# Clean and convert the date field\n",
    "news_df[\"datetime\"] = pd.to_datetime(news_df[\"seendate\"], format=\"%Y%m%dT%H%M%SZ\")\n",
    "news_df[\"date\"] = news_df[\"datetime\"].dt.date\n",
    "\n",
    "# Rename columns for clarity\n",
    "news_df = news_clean.copy()\n",
    "\n",
    "news_df[\"datetime\"] = pd.to_datetime(news_df[\"seendate\"], format=\"%Y%m%dT%H%M%SZ\")\n",
    "news_df[\"date\"] = news_df[\"datetime\"].dt.date\n",
    "\n",
    "news_df = news_df.rename(columns={\n",
    "    \"domain\": \"source\",\n",
    "    \"fulltext\": \"text\",\n",
    "})\n",
    "\n",
    "\n",
    "news_df = news_df[[\"datetime\", \"date\", \"source\", \"title\", \"text\", \"clean_text\", \"topic\", \"topic_probmax\"]]\n",
    "\n",
    "print(topic_model.get_topic_info())\n",
    "\n",
    "df_time = news_df[[\"clean_text\", \"datetime\", \"topic\"]].rename(columns={\n",
    "    \"clean_text\": \"Document\",\n",
    "    \"datetime\": \"Timestamp\",\n",
    "    \"topic\": \"Topic\",\n",
    "})\n",
    "\n",
    "topics_over_time = topic_model.topics_over_time(\n",
    "    docs=df_time[\"Document\"].tolist(),\n",
    "    topics=df_time[\"Topic\"].tolist(),\n",
    "    timestamps=df_time[\"Timestamp\"].tolist()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b9214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Coherence: 0.34113429785470195\n",
      "[0.05195506 0.02970905]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "0_payment_blockchain_stable...",
          "1_blockchain_digital_asset"
         ],
         "xaxis": "x",
         "y": [
          "0_payment_blockchain_stable...",
          "1_blockchain_digital_asset"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "BACAPySYXz8kmF8//v9/Pw==",
          "dtype": "f4",
          "shape": "2, 2"
         }
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Similarity Score"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ]
        },
        "height": 800,
        "hoverlabel": {
         "bgcolor": "white",
         "font": {
          "family": "Rockwell",
          "size": 16
         }
        },
        "legend": {
         "title": {
          "text": "Trend"
         }
        },
        "margin": {
         "t": 60
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "Black",
          "size": 22
         },
         "text": "<b>Similarity Matrix</b>",
         "x": 0.55,
         "xanchor": "center",
         "y": 0.95,
         "yanchor": "top"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -------- 3. Evaluation of BERTopic clusters --------\n",
    "\n",
    "topics_words = []\n",
    "for topic_id in set(topics):\n",
    "    if topic_id == -1: continue\n",
    "    words = [w for w, _ in topic_model.get_topic(topic_id)]\n",
    "    topics_words.append(words)\n",
    "    \n",
    "# Measure how words within topics relate to each other\n",
    "docs_tokenized = [doc.split() for doc in news_df[\"text\"]]\n",
    "\n",
    "\n",
    "MAX_DOCS = 300\n",
    "if len(docs_tokenized) > MAX_DOCS:\n",
    "    docs_tokenized_sample = sample(docs_tokenized, MAX_DOCS)\n",
    "else:\n",
    "    docs_tokenized_sample = docs_tokenized\n",
    "\n",
    "dictionary = Dictionary(docs_tokenized)\n",
    "\n",
    "# 'c_v' is a commonly used topic coherence measure\n",
    "cm = CoherenceModel(\n",
    "    topics=topics_words,\n",
    "    texts=docs_tokenized,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v',\n",
    "    processes=4\n",
    ")\n",
    "\n",
    "coherence = cm.get_coherence()\n",
    "print(\"Topic Coherence:\", coherence)\n",
    "\n",
    "# HDBSCAN cluster stability (cluster persistence: higher means more stable)\n",
    "\n",
    "clusterer = topic_model.hdbscan_model\n",
    "stabilities = clusterer.cluster_persistence_\n",
    "print(stabilities)\n",
    "\n",
    "# Some visualizations may not work if there are too few topics\n",
    "\n",
    "topic_model.visualize_topics_over_time(topics_over_time)\n",
    "topic_model.visualize_barchart(top_n_topics=10)\n",
    "topic_model.visualize_heatmap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25666e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gasto\\AppData\\Local\\Temp\\ipykernel_25824\\3719816045.py:52: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params optimisés: {'ws': np.float64(0.8369760451530115), 'wt': np.float64(0.8369760451530115), 'wr': np.float64(0.8369760451530115), 'wl': np.float64(0.8369760451530115), 'wb': np.float64(0.8369760451530115)}\n",
      "        date   sent_rl\n",
      "0 2025-10-31 -4.047515\n",
      "1 2025-11-01  0.896683\n",
      "2 2025-11-02  4.138598\n",
      "3 2025-11-03 -1.116493\n",
      "4 2025-11-04 -1.979591\n",
      "                                               title  sent_neg  sent_neu  \\\n",
      "0  Blockchain for Good Alliance ( BGA ) Recognize...  0.714756  0.009995   \n",
      "1  Digital South Trust Launches India First & Lar...  0.857132  0.009265   \n",
      "4  Credit Blockchain Launches Next - Generation A...  0.638664  0.011034   \n",
      "5  Global Blockchain Show 2025 by VAP Group to be...  0.188980  0.008485   \n",
      "6  Mumbai blockchain moment : Binance Yatra maps ...  0.120096  0.009419   \n",
      "\n",
      "   sent_pos   sent_rl  \n",
      "0  0.275249 -0.899104  \n",
      "1  0.133603 -1.357305  \n",
      "4  0.350302 -0.664776  \n",
      "5  0.802535  1.086591  \n",
      "6  0.870485  1.746366  \n"
     ]
    }
   ],
   "source": [
    "#-------- 4. Sentiment analysis with FinBERT --------\n",
    "\n",
    "# Load the FinBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Define a helper to compute sentiment probabilities using FinBERT\n",
    "def finbert_sentiment(text):\n",
    "    try:\n",
    "        # avoid errors for None or very short texts\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return (0, 1, 0)\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            text[:512],                # truncate to avoid GPU/CPU errors\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=1).numpy()[0]\n",
    "\n",
    "        return float(probs[0]), float(probs[1]), float(probs[2])  # neg, neu, pos\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error processing text:\", e)\n",
    "        return (0, 1, 0)\n",
    "\n",
    "# Apply the sentiment function to each article text\n",
    "sentiments = news_df[\"text\"].apply(finbert_sentiment)\n",
    "\n",
    "news_df[\"sent_neg\"] = sentiments.apply(lambda x: x[0])\n",
    "news_df[\"sent_neu\"] = sentiments.apply(lambda x: x[1])\n",
    "news_df[\"sent_pos\"] = sentiments.apply(lambda x: x[2])\n",
    "\n",
    "\n",
    "\n",
    "# ========= 1) FEATURES FOR REINFORCEMENT / SCORING =========\n",
    "\n",
    "# Sentiment intensity (distance from neutral; larger magnitude = stronger sentiment)\n",
    "news_df[\"sent_dir\"] = news_df[\"sent_pos\"] - news_df[\"sent_neg\"]\n",
    "\n",
    "# Normalized text length\n",
    "news_df[\"length_norm\"] = news_df[\"text\"].str.len() / news_df[\"text\"].str.len().max()\n",
    "\n",
    "# Source weight: less frequent sources receive higher relative weight\n",
    "source_freq = news_df[\"source\"].value_counts()\n",
    "source_importance = 1 / (1 + source_freq)\n",
    "news_df[\"source_weight\"] = news_df[\"source\"].map(source_importance).fillna(0.5)\n",
    "\n",
    "# Recency weight: exponential decay (half-life ≈ 24h)\n",
    "news_df[\"hours_since\"] = (datetime.utcnow() - news_df[\"datetime\"]).dt.total_seconds() / 3600\n",
    "news_df[\"recency_weight\"] = np.exp(- news_df[\"hours_since\"] / 24)  # half-life ≈ 24h\n",
    "\n",
    "# ========= 2) RL LOOP TO OPTIMIZE FEATURE WEIGHTS =========\n",
    "\n",
    "# initial parameters (weights for the feature components)\n",
    "params = {\n",
    "    \"ws\": 1.0,  # weight for sentiment strength\n",
    "    \"wt\": 1.0,  # weight for topic probability max\n",
    "    \"wr\": 1.0,  # weight for recency\n",
    "    \"wl\": 1.0,  # weight for text length\n",
    "    \"wb\": 1.0   # weight for source importance\n",
    "}\n",
    "\n",
    "def compute_rl_sentiment(df, params):\n",
    "    return (\n",
    "        (1  +\n",
    "        params[\"wt\"] * df[\"topic_probmax\"] +\n",
    "        params[\"wr\"] * df[\"recency_weight\"] +\n",
    "        params[\"wl\"] * df[\"length_norm\"] +\n",
    "        params[\"wb\"] * df[\"source_weight\"]) * df[\"sent_dir\"]\n",
    "    )\n",
    "\n",
    "lr = 0.01  # learning rate for the simple parameter update\n",
    "\n",
    "# Ensure `prices_daily['date']` and `news_df['date']` are datetime\n",
    "prices_daily[\"date\"] = pd.to_datetime(prices_daily[\"date\"])\n",
    "news_df[\"date\"] = pd.to_datetime(news_df[\"date\"])\n",
    "\n",
    "for epoch in range(200):\n",
    "    # 1) compute per-article RL score\n",
    "    news_df[\"sent_rl\"] = compute_rl_sentiment(news_df, params)\n",
    "\n",
    "    # 2) aggregate scores by day (sum = volume * intensity)\n",
    "    sent_daily = (\n",
    "        news_df\n",
    "        .groupby(\"date\")[\"sent_rl\"]\n",
    "        .sum()\n",
    "        .reset_index()   # columns: date, sent_rl\n",
    "    )\n",
    "\n",
    "    # 3) merge daily sentiment with price returns\n",
    "    df_tmp = pd.merge(\n",
    "        prices_daily[[\"date\", \"return\"]],\n",
    "        sent_daily,\n",
    "        on=\"date\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # 4) compute correlation between yesterday's sentiment and today's return\n",
    "    corr = df_tmp[\"sent_rl\"].shift(1).corr(df_tmp[\"return\"])\n",
    "\n",
    "    if pd.isna(corr):\n",
    "        continue  # skip if there is not enough data to compute correlation\n",
    "\n",
    "    # 5) simple 'gradient ascent': nudge all params in direction of the correlation\n",
    "    for k in params:\n",
    "        params[k] += lr * corr\n",
    "\n",
    "print(\"optimized params:\", params)\n",
    "\n",
    "# ========= 3) FINAL SCORE PER ARTICLE AND PER DAY =========\n",
    "\n",
    "# Recompute once with the optimized parameters\n",
    "news_df[\"sent_rl\"] = compute_rl_sentiment(news_df, params)\n",
    "\n",
    "# Per day (sum = volume * intensity)\n",
    "sent_daily_rl = (\n",
    "    news_df\n",
    "    .groupby(\"date\")[\"sent_rl\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(sent_daily_rl.head())\n",
    "\n",
    "\n",
    "print(news_df[[\"title\", \"sent_neg\", \"sent_neu\", \"sent_pos\", \"sent_rl\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634e29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date          price    return  topic_-1  topic_0  topic_1   sent_rl\n",
      "0  2025-10-26  114472.445312  0.000000       0.0      0.0      0.0  0.000000\n",
      "1  2025-10-27  114119.328125 -0.003085       0.0      0.0      0.0  0.000000\n",
      "2  2025-10-28  112956.164062 -0.010193       0.0      0.0      0.0  0.000000\n",
      "3  2025-10-29  110055.304688 -0.025681       0.0      0.0      0.0  0.000000\n",
      "4  2025-10-30  108305.546875 -0.015899       0.0      0.0      0.0  0.000000\n",
      "5  2025-10-31  109556.164062  0.011547       2.0      0.0      1.0 -4.047515\n",
      "6  2025-11-01  110064.015625  0.004636       0.0      1.0      0.0  0.896683\n",
      "7  2025-11-02  110639.625000  0.005230       2.0      2.0      0.0  4.138598\n",
      "8  2025-11-03  106547.523438 -0.036986       1.0      0.0      0.0 -1.116493\n",
      "9  2025-11-04  101590.523438 -0.046524       1.0      1.0      0.0 -1.979591\n",
      "return      1.000000\n",
      "topic_1     0.133762\n",
      "sent_rl     0.123552\n",
      "topic_0     0.040156\n",
      "price       0.023667\n",
      "topic_-1   -0.089742\n",
      "Name: return, dtype: float64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 1) Number of news per topic per day\n",
    "topic_daily_counts = (\n",
    "    news_df\n",
    "    .groupby([\"date\", \"topic\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# 2) Pivot: rows = dates, columns = topics\n",
    "topic_daily_pivot = topic_daily_counts.pivot(\n",
    "    index=\"date\", columns=\"topic\", values=\"count\"\n",
    ").fillna(0)\n",
    "\n",
    "topic_daily_pivot.columns = [f\"topic_{c}\" for c in topic_daily_pivot.columns]\n",
    "topic_daily_pivot.index = pd.to_datetime(topic_daily_pivot.index)\n",
    "topic_daily_pivot = topic_daily_pivot.reset_index()   # 'date' becomes a column again\n",
    "\n",
    "# 3) Daily aggregated RL sentiment\n",
    "topic_daily_pivot[\"date\"] = pd.to_datetime(topic_daily_pivot[\"date\"])\n",
    "sent_daily_rl[\"date\"] = pd.to_datetime(sent_daily_rl[\"date\"])\n",
    "\n",
    "# 4) Combine topic counts with RL sentiment features\n",
    "daily_features = pd.merge(\n",
    "    topic_daily_pivot,\n",
    "    sent_daily_rl,      \n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# 5) Merge with price data\n",
    "prices_daily[\"date\"] = pd.to_datetime(prices_daily[\"date\"]).dt.date\n",
    "daily_features[\"date\"] = pd.to_datetime(daily_features[\"date\"]).dt.date\n",
    "\n",
    "df_join = pd.merge(\n",
    "    prices_daily,\n",
    "    daily_features,\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "print(df_join.head(10))\n",
    "\n",
    "# 6) Correlations with return\n",
    "corr = df_join.corr(numeric_only=True)[\"return\"].sort_values(ascending=False)\n",
    "print(corr)\n",
    "\n",
    "topic_id = 3\n",
    "print(topic_model.get_topic(topic_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898f94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18181818181818182\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "AUC: 0.07142857142857145\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31         7\n",
      "           1       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.18        11\n",
      "   macro avg       0.17      0.14      0.15        11\n",
      "weighted avg       0.21      0.18      0.20        11\n",
      "\n",
      "\n",
      "=== Feature Importance ===\n",
      "    feature      coef\n",
      "0  topic_-1  0.751712\n",
      "1   topic_0  0.339026\n",
      "2   topic_1  0.126523\n",
      "3   sent_rl -1.035602\n"
     ]
    }
   ],
   "source": [
    "# ====== 1. Prepare ML dataset ======\n",
    "df_ml = df_join.copy()\n",
    "df_ml = df_ml.sort_values(\"date\")\n",
    "df_ml[\"return_next\"] = df_ml[\"return\"].shift(-1)\n",
    "df_ml[\"up\"] = (df_ml[\"return_next\"] > 0).astype(int)\n",
    "df_ml = df_ml.dropna(subset=[\"return_next\"])\n",
    "\n",
    "topic_cols = [c for c in df_ml.columns if c.startswith(\"topic_\")]\n",
    "feat_cols = topic_cols + [\"sent_rl\"]\n",
    "\n",
    "X = df_ml[feat_cols]\n",
    "y = df_ml[\"up\"]\n",
    "\n",
    "# ====== 2. Time-based train/test split ======\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=False\n",
    ")\n",
    "\n",
    "# ====== 3. Model ======\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ====== 4. Metrics ======\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1:\", f1_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ====== 5. Feature importance ======\n",
    "\n",
    "logreg = clf.named_steps[\"logreg\"]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feat_cols,\n",
    "    \"coef\": logreg.coef_[0]   # coefficient vector for class 1\n",
    "}).sort_values(\"coef\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(coef_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
